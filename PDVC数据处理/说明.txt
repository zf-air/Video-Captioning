1. 任务主要是将skeleton数据转化为特征的格式来进行实验。
2. skeleton数据，每个视频一个mat文件，mat文件保存的是(n,60)的矩阵，N代表视频的帧数，60代表，20个关节点，每个关节点有(x,y,z)三个坐标来表示，一共是20*3=60位数据.
3.data_split中是标注的时间切分点的数据，因为我实验的时候将描述的准备阶段和结束阶段去除掉了，只剩下动作阶段，所以所有的视频处理时都需要截取中间的一部分作为实验数据。
a005开头的视频没有准备动作（Begin in standing position with arms beside body.），其他的都有。结束动作则是（Return to starting position.）
PDF中    A.3.1 Textual instructions     的描述，Start-Seg0代表第一条描述，Seg0-Seg1代表第二条描述,依此类推。
例如a001_s001_e001: 截取的部分为Seg1-Seg4，即0-7秒，（由于视频的帧率是一秒15帧），所以是0-105帧。
例如a005_s001_e001: 截取的部分为Start-Seg3，即0-5.5秒，（由于原实验特征取的是整数），所以是0-75帧。（5.5向下取整为5）。
4.原实验的特征数据格式为（n,512）,N为视频的时间（秒），512=16*32,代表16帧，一帧32位数据，而现在改为skeleton数据则是需要改为（n,900），900=15*60,15代表帧数，60代表关节点的坐标。
5.WorkoutUOW18_read_skeleton.py中的代码，是提取出关节点x,y,z的代码，你可以借鉴一下。